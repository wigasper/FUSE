{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Default threshold function\n",
    "def get_f1(thresh_constant, term_freqs, solution):\n",
    "    # Predict\n",
    "    predictions = {}\n",
    "    for doc in term_freqs.keys():\n",
    "        mean_freq = sum(term_freqs[doc].values()) / len(term_freqs[doc])\n",
    "        predictions[doc] = [key for key, val in term_freqs[doc].items() if val > (mean_freq + thresh_constant)]\n",
    "        \n",
    "    # Get evaluation metrics\n",
    "    true_pos = 0\n",
    "    false_pos = 0\n",
    "    false_neg = 0\n",
    "    \n",
    "    for pmid in predictions:\n",
    "        true_pos += len([pred for pred in predictions[pmid] if pred in solution[pmid]])\n",
    "        false_pos += len([pred for pred in predictions[pmid] if pred not in solution[pmid]])\n",
    "        false_neg += len([sol for sol in solution[pmid] if sol not in predictions[pmid]])\n",
    "\n",
    "    if true_pos == 0:\n",
    "        precision = 0\n",
    "        recall = 0\n",
    "        f1 = 0\n",
    "    else:\n",
    "        precision = true_pos / (true_pos + false_pos)\n",
    "        recall = true_pos / (true_pos + false_neg)\n",
    "        f1 = (2 * precision * recall) / (precision + recall)\n",
    "    \n",
    "    return f1\n",
    "\n",
    "def train(term_freqs, solution):\n",
    "    curr_thresh_constant = 0.0\n",
    "    step_val = 0.001\n",
    "    f1s = []\n",
    "    \n",
    "    f1s.append(get_f1(curr_thresh_constant, term_freqs, solution))\n",
    "    f1s.append(get_f1(curr_thresh_constant + step_val, term_freqs, solution))\n",
    "    \n",
    "    curr_thresh_constant += step_val\n",
    "    next_thresh_f1 = get_f1(curr_thresh_constant + step_val, term_freqs, solution)\n",
    "    \n",
    "    while not (next_thresh_f1 < f1s[-1] and next_thresh_f1 < f1s[-2] and f1s[-1] < f1s[-2]):\n",
    "        curr_thresh_constant += step_val\n",
    "        f1s.append(get_f1(curr_thresh_constant, term_freqs, solution))\n",
    "        next_thresh_f1 = get_f1(curr_thresh_constant + step_val, term_freqs, solution)\n",
    "    \n",
    "    return curr_thresh_constant - step_val\n",
    "\n",
    "def predict(test_freqs, thresh_constant):\n",
    "    # Test it out\n",
    "    predictions = {}\n",
    "\n",
    "    # Predict\n",
    "    for doc in test_freqs.keys():\n",
    "        mean_freq = sum(test_freqs[doc].values()) / len(test_freqs[doc])\n",
    "        predictions[doc] = [key for key, val in test_freqs[doc].items() if val > (mean_freq + thresh_constant)]\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in term frequencies and partition\n",
    "with open(\"./data/term_freqs_rev_3_all_terms.json\", \"r\") as handle:\n",
    "    temp = json.load(handle)\n",
    "\n",
    "docs_list = list(temp.keys())\n",
    "partition = int(len(docs_list) * .8)\n",
    "\n",
    "train_docs = docs_list[0:partition]\n",
    "test_docs = docs_list[partition:]\n",
    "\n",
    "# Load in solution values\n",
    "solution = {}\n",
    "docs_list = set(docs_list)\n",
    "with open(\"./data/pm_doc_term_counts.csv\", \"r\") as handle:\n",
    "    for line in handle:\n",
    "        line = line.strip(\"\\n\").split(\",\")\n",
    "        if line[0] in docs_list:\n",
    "            # Only use samples indexed with MeSH terms\n",
    "            terms = [term for term in line[1:] if term]\n",
    "            if terms:\n",
    "                solution[line[0]] = terms\n",
    "                \n",
    "# Build training/test data, ensure good solution data is available\n",
    "# Solution data is not always available because documents may not be\n",
    "# indexed - even though obviously some of their references have been indexed\n",
    "train_freqs = {}\n",
    "for doc in train_docs:\n",
    "    if doc in solution.keys():\n",
    "        train_freqs[doc] = temp[doc]\n",
    "\n",
    "test_freqs = {}\n",
    "for doc in test_docs:\n",
    "    if doc in solution.keys():\n",
    "        test_freqs[doc] = temp[doc]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in MeSH data\n",
    "term_names = {}\n",
    "mean_term_depths = {}\n",
    "with open(\"./data/mesh_data.tab\", \"r\") as handle:\n",
    "    for line in handle:\n",
    "        line = line.strip(\"\\n\").split(\"\\t\")\n",
    "        term_names[line[0]] = line[1]\n",
    "        mean_depth = 0\n",
    "        posits = [len(posit.split(\".\")) for posit in line[4].split(\",\")]\n",
    "        mean_term_depths[line[0]] = sum(posits) / len(posits)\n",
    "            \n",
    "uids = list(term_names.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned discrimination threshold constant: 0.009000000000000001\n",
      "\n",
      "Micro-averaged F1 from test set: 0.4798893772454778\n",
      "Micro-averaged precision from test set: 0.5024845355903074\n",
      "Micro-averaged recall from test set: 0.4592388424940755\n",
      "\n",
      "Macro-averaged F1 from test set: 0.28809422130121976\n",
      "Macro-averaged precision from test set: 0.38261781501437614\n",
      "Macro-averaged recall from test set: 0.26782157999696654\n",
      "\n",
      "Example-based F1 from test set: 0.47100622014450827\n",
      "Example-based precision from test set: 0.5087594123136442\n",
      "Example-based recall from test set: 0.48054287510120836\n",
      "\n"
     ]
    }
   ],
   "source": [
    "thresh_constant = train(train_freqs, solution)\n",
    "print(f\"Learned discrimination threshold constant: {thresh_constant}\\n\")\n",
    "\n",
    "preds = predict(test_freqs, thresh_constant)\n",
    "\n",
    "true_pos = 0\n",
    "false_pos = 0\n",
    "false_neg = 0\n",
    "\n",
    "for pmid in preds:\n",
    "    true_pos += len([pred for pred in preds[pmid] if pred in solution[pmid]])\n",
    "    false_pos += len([pred for pred in preds[pmid] if pred not in solution[pmid]])\n",
    "    false_neg += len([sol for sol in solution[pmid] if sol not in preds[pmid]])\n",
    "\n",
    "if true_pos == 0:\n",
    "    mi_precision = 0\n",
    "    mi_recall = 0\n",
    "    mi_f1 = 0\n",
    "else:\n",
    "    mi_precision = true_pos / (true_pos + false_pos)\n",
    "    mi_recall = true_pos / (true_pos + false_neg)\n",
    "    mi_f1 = (2 * mi_precision * mi_recall) / (mi_precision + mi_recall)\n",
    "\n",
    "print(f\"Micro-averaged F1 from test set: {mi_f1}\")\n",
    "print(f\"Micro-averaged precision from test set: {mi_precision}\")\n",
    "print(f\"Micro-averaged recall from test set: {mi_recall}\\n\")\n",
    "\n",
    "ma_ps = []\n",
    "ma_rs = []\n",
    "ma_f1s = []\n",
    "\n",
    "for uid in uids:\n",
    "    true_pos = 0\n",
    "    false_pos = 0\n",
    "    false_neg = 0\n",
    "    \n",
    "    for pmid in preds:\n",
    "        if uid in preds[pmid] and uid in solution[pmid]:\n",
    "            true_pos += 1\n",
    "        if uid in preds[pmid] and uid not in solution[pmid]:\n",
    "            false_pos += 1\n",
    "        if uid in solution[pmid] and uid not in preds[pmid]:\n",
    "            false_neg += 1\n",
    "    \n",
    "    if true_pos == 0:\n",
    "        ma_precision = 0\n",
    "        ma_recall = 0\n",
    "        ma_f1 = 0\n",
    "    else:\n",
    "        ma_precision = true_pos / (true_pos + false_pos)\n",
    "        ma_recall = true_pos / (true_pos + false_neg)\n",
    "        ma_f1 = (2 * ma_precision * ma_recall) / (ma_precision + ma_recall)\n",
    "\n",
    "    if true_pos + false_pos + false_neg > 0:\n",
    "        ma_ps.append(ma_precision)\n",
    "        ma_rs.append(ma_recall)\n",
    "        ma_f1s.append(ma_f1)\n",
    "\n",
    "ma_f1 = sum(ma_f1s) / len(ma_f1s)\n",
    "ma_recall = sum(ma_rs) / len(ma_rs)\n",
    "ma_precision = sum(ma_ps) / len(ma_ps)\n",
    "\n",
    "print(f\"Macro-averaged F1 from test set: {ma_f1}\")\n",
    "print(f\"Macro-averaged precision from test set: {ma_precision}\")\n",
    "print(f\"Macro-averaged recall from test set: {ma_recall}\\n\")\n",
    "\n",
    "eb_ps = []\n",
    "eb_rs = []\n",
    "eb_f1s = []\n",
    "\n",
    "for pmid in preds:\n",
    "    true_pos = len([pred for pred in preds[pmid] if pred in solution[pmid]])\n",
    "    false_pos = len([pred for pred in preds[pmid] if pred not in solution[pmid]])\n",
    "    false_neg = len([sol for sol in solution[pmid] if sol not in preds[pmid]])\n",
    "\n",
    "    if true_pos == 0:\n",
    "        eb_precision = 0\n",
    "        eb_recall = 0\n",
    "        eb_f1 = 0\n",
    "    else:\n",
    "        eb_precision = true_pos / (true_pos + false_pos)\n",
    "        eb_recall = true_pos / (true_pos + false_neg)\n",
    "        eb_f1 = (2 * eb_precision * eb_recall) / (eb_precision + eb_recall)\n",
    "\n",
    "    eb_ps.append(eb_precision)\n",
    "    eb_rs.append(eb_recall)\n",
    "    eb_f1s.append(eb_f1)\n",
    "\n",
    "eb_f1 = sum(eb_f1s) / len(eb_f1s)\n",
    "eb_recall = sum(eb_rs) / len(eb_rs)\n",
    "eb_precision = sum(eb_ps) / len(eb_ps)\n",
    "\n",
    "print(f\"Example-based F1 from test set: {eb_f1}\")\n",
    "print(f\"Example-based precision from test set: {eb_precision}\")\n",
    "print(f\"Example-based recall from test set: {eb_recall}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_freqs, thresh_constant, solution):\n",
    "    predictions = {}\n",
    "    f1s = {}\n",
    "    f1s_all = {}\n",
    "    \n",
    "    # Predict\n",
    "    for doc in test_freqs.keys():\n",
    "        mean_freq = sum(test_freqs[doc].values()) / len(test_freqs[doc])\n",
    "        predictions[doc] = [key for key, val in test_freqs[doc].items() if val > (mean_freq + thresh_constant)]\n",
    "\n",
    "    for pmid in predictions:\n",
    "        true_pos = len([pred for pred in predictions[pmid] if pred in solution[pmid]])\n",
    "        false_pos = len([pred for pred in predictions[pmid] if pred not in solution[pmid]])\n",
    "        false_neg = len([sol for sol in solution[pmid] if sol not in predictions[pmid]])\n",
    "\n",
    "        if true_pos == 0:\n",
    "            precision = 0\n",
    "            recall = 0\n",
    "            f1 = 0\n",
    "        else:\n",
    "            precision = true_pos / (true_pos + false_pos)\n",
    "            recall = true_pos / (true_pos + false_neg)\n",
    "            f1 = (2 * precision * recall) / (precision + recall)\n",
    "        if len(predictions[pmid]) > 20:\n",
    "            f1s[pmid] = f1\n",
    "            \n",
    "        f1s_all[pmid] = f1\n",
    "        \n",
    "    return f1s, f1s_all, predictions\n",
    "        \n",
    "f1s, f1s_all, predictions = predict(test_freqs, thresh_constant, solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum F1: 0.8\n",
      "Minimum F1: 0.07692307692307693\n"
     ]
    }
   ],
   "source": [
    "max_f1 = max(f1s.values())\n",
    "min_f1 = min(f1s.values())\n",
    "\n",
    "sorted_f1s = sorted([[key, val] for key, val in f1s.items()], key=lambda item: item[1], reverse=True)\n",
    "max_pmids = sorted_f1s[0:10]\n",
    "med_pmids = [samp for samp in sorted_f1s if samp[1] > 0.44 and samp[1] < 0.46][0:15]\n",
    "sorted_f1s_all = sorted([[key, val] for key, val in f1s_all.items()], key=lambda item: item[1], reverse=True)\n",
    "min_pmids = sorted_f1s_all[-10:]\n",
    "\n",
    "print(f\"Maximum F1: {max_f1}\")\n",
    "print(f\"Minimum F1: {min_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for 25686058: 0.8\n",
      "Predicted terms (22) for PMID 25686058: \n",
      "Adult; Aged; Aged, 80 and over; Angiogenesis Inhibitors; Antibodies, Monoclonal, Humanized; Bevacizumab; Female; Fluorescein Angiography; Glucocorticoids; Humans; Injections; Macular Edema; Male; Middle Aged; Retinal Vein Occlusion; Retrospective Studies; Tomography, Optical Coherence; Treatment Outcome; Triamcinolone Acetonide; Vascular Endothelial Growth Factor A; Visual Acuity; Vitreous Body\n",
      "\n",
      "Actual terms (23) applied to PMID 25686058: \n",
      "Adult; Aged; Aged, 80 and over; Angiogenesis Inhibitors; Bevacizumab; Dose-Response Relationship, Drug; Female; Fluorescein Angiography; Follow-Up Studies; Fundus Oculi; Glucocorticoids; Humans; Intravitreal Injections; Macular Edema; Male; Middle Aged; Retinal Vein Occlusion; Retrospective Studies; Time Factors; Tomography, Optical Coherence; Treatment Outcome; Triamcinolone Acetonide; Visual Acuity\n",
      "\n",
      "Number of MeSH terms applied to all of 25686058's references: 84\n",
      "\n",
      "F1 score for 21364592: 0.7804878048780488\n",
      "Predicted terms (21) for PMID 21364592: \n",
      "Adult; Aged; Alleles; Antineoplastic Combined Chemotherapy Protocols; Aryl Hydrocarbon Hydroxylases; Cisplatin; Cytochrome P-450 CYP2A6; DNA Repair; DNA-Binding Proteins; Female; Fluorouracil; Genotype; Humans; Male; Middle Aged; Mixed Function Oxygenases; Oxonic Acid; Polymorphism, Genetic; Stomach Neoplasms; Tegafur; Treatment Outcome\n",
      "\n",
      "Actual terms (20) applied to PMID 21364592: \n",
      "Adult; Aged; Antineoplastic Combined Chemotherapy Protocols; Aryl Hydrocarbon Hydroxylases; Cisplatin; Cytochrome P-450 CYP2A6; DNA-Binding Proteins; Drug Combinations; Endonucleases; Female; Genotype; Humans; Male; Middle Aged; Neoplasm Metastasis; Oxonic Acid; Polymorphism, Genetic; Stomach Neoplasms; Tegafur; X-ray Repair Cross Complementing Protein 1\n",
      "\n",
      "Number of MeSH terms applied to all of 21364592's references: 197\n"
     ]
    }
   ],
   "source": [
    "max_preds = \"; \".join(sorted([term_names[pred] for pred in predictions[max_pmids[0][0]]]))\n",
    "max_sol = \"; \".join(sorted(list(dict.fromkeys([term_names[sol] for sol in solution[max_pmids[0][0]]]))))\n",
    "print(f\"F1 score for {max_pmids[0][0]}: {f1s[max_pmids[0][0]]}\")\n",
    "print(f\"Predicted terms ({len(predictions[max_pmids[0][0]])}) for PMID {max_pmids[0][0]}: \\n{max_preds}\")\n",
    "print(f\"\\nActual terms ({len(solution[max_pmids[0][0]])}) applied to PMID {max_pmids[0][0]}: \\n{max_sol}\")\n",
    "print(f\"\\nNumber of MeSH terms applied to all of {max_pmids[0][0]}'s references: {len(test_freqs[max_pmids[0][0]].keys())}\\n\")\n",
    "\n",
    "max_preds = \"; \".join(sorted([term_names[pred] for pred in predictions[max_pmids[1][0]]]))\n",
    "max_sol = \"; \".join(sorted([term_names[sol] for sol in solution[max_pmids[1][0]]]))\n",
    "print(f\"F1 score for {max_pmids[1][0]}: {f1s[max_pmids[1][0]]}\")\n",
    "print(f\"Predicted terms ({len(predictions[max_pmids[1][0]])}) for PMID {max_pmids[1][0]}: \\n{max_preds}\")\n",
    "print(f\"\\nActual terms ({len(solution[max_pmids[1][0]])}) applied to PMID {max_pmids[1][0]}: \\n{max_sol}\")\n",
    "print(f\"\\nNumber of MeSH terms applied to all of {max_pmids[1][0]}'s references: {len(test_freqs[max_pmids[1][0]].keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for 26160390: 0\n",
      "Predicted terms (4) for PMID 26160390: \n",
      "Fungi; Molecular Structure; Plants; Species Specificity\n",
      "\n",
      "Actual terms (8) applied to PMID 26160390: \n",
      "Anti-Infective Agents; Bacteria; Endophytes; Fusarium; Microbial Sensitivity Tests; Opuntia; Pyrrolidinones; Tetrahydronaphthalenes\n",
      "\n",
      "Number of MeSH terms applied to all of 26160390's references: 65\n",
      "\n",
      "F1 score for 25609924: 0\n",
      "Predicted terms (9) for PMID 25609924: \n",
      "Animals; Antioxidants; Cholesterol; Flavonoids; Humans; Lipoproteins, LDL; Male; Phenols; Rats\n",
      "\n",
      "Actual terms (11) applied to PMID 25609924: \n",
      "Chromatography, High Pressure Liquid; Chromatography, Reverse-Phase; Gas Chromatography-Mass Spectrometry; Hydroxymethylglutaryl-CoA Reductase Inhibitors; Hypercholesterolemia; Magnoliopsida; Phytotherapy; Plant Extracts; Plant Leaves; Plants, Medicinal; Tandem Mass Spectrometry\n",
      "\n",
      "Number of MeSH terms applied to all of 25609924's references: 298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "examining = min_pmids[3][0]\n",
    "min_preds = \"; \".join(sorted([term_names[pred] for pred in predictions[examining]]))\n",
    "min_sol = \"; \".join(sorted(list(dict.fromkeys([term_names[sol] for sol in solution[examining]]))))\n",
    "print(f\"F1 score for {examining}: {f1s_all[examining]}\")\n",
    "print(f\"Predicted terms ({len(predictions[examining])}) for PMID {examining}: \\n{min_preds}\")\n",
    "print(f\"\\nActual terms ({len(solution[examining])}) applied to PMID {examining}: \\n{min_sol}\")\n",
    "print(f\"\\nNumber of MeSH terms applied to all of {examining}'s references: {len(test_freqs[examining].keys())}\\n\")\n",
    "\n",
    "min_preds = \"; \".join(sorted([term_names[pred] for pred in predictions[min_pmids[1][0]]]))\n",
    "min_sol = \"; \".join(sorted(list(dict.fromkeys([term_names[sol] for sol in solution[min_pmids[1][0]]]))))\n",
    "print(f\"F1 score for {min_pmids[1][0]}: {f1s_all[min_pmids[1][0]]}\")\n",
    "print(f\"Predicted terms ({len(predictions[min_pmids[1][0]])}) for PMID {min_pmids[1][0]}: \\n{min_preds}\")\n",
    "print(f\"\\nActual terms ({len(solution[min_pmids[1][0]])}) applied to PMID {min_pmids[1][0]}: \\n{min_sol}\")\n",
    "print(f\"\\nNumber of MeSH terms applied to all of {min_pmids[1][0]}'s references: {len(test_freqs[min_pmids[1][0]].keys())}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for 29351962: 0.45161290322580644\n",
      "Predicted terms (21) for PMID 29351962: \n",
      "Amino Acid Sequence; Bacterial Proteins; DEAD-box RNA Helicases; Endoribonucleases; Escherichia coli; Escherichia coli Proteins; Exoribonucleases; Models, Molecular; Molecular Sequence Data; Multienzyme Complexes; Nucleic Acid Conformation; Polyribonucleotide Nucleotidyltransferase; Protein Binding; Protein Structure, Tertiary; RNA; RNA Helicases; RNA Stability; RNA, Bacterial; RNA, Messenger; Saccharomyces cerevisiae; Saccharomyces cerevisiae Proteins\n",
      "\n",
      "Actual terms (10) applied to PMID 29351962: \n",
      "Bacteria; DEAD-box RNA Helicases; Endoribonucleases; Exosomes; Mitochondria; Multienzyme Complexes; Polyribonucleotide Nucleotidyltransferase; RNA; RNA Helicases; RNA Stability\n",
      "\n",
      "Number of MeSH terms applied to all of 29351962's references: 271\n",
      "\n",
      "F1 score for 20170555: 0.4571428571428571\n",
      "Predicted terms (21) for PMID 20170555: \n",
      "Adolescent; Adult; Aged; Antigens, Bacterial; Antitubercular Agents; BCG Vaccine; Child; Cost-Benefit Analysis; Enzyme-Linked Immunosorbent Assay; Female; Humans; Interferon-gamma; Isoniazid; Male; Mass Screening; Middle Aged; Mycobacterium tuberculosis; Sensitivity and Specificity; Tuberculin Test; Tuberculosis; Tuberculosis, Pulmonary\n",
      "\n",
      "Actual terms (14) applied to PMID 20170555: \n",
      "Contact Tracing; Cost-Benefit Analysis; Decision Trees; Enzyme-Linked Immunosorbent Assay; Health Care Costs; Humans; Incidence; Interferon-gamma; Mass Screening; Prevalence; Sensitivity and Specificity; Tuberculin Test; Tuberculosis, Pulmonary; United Kingdom\n",
      "\n",
      "Number of MeSH terms applied to all of 20170555's references: 179\n"
     ]
    }
   ],
   "source": [
    "curr_pmid = med_pmids[4][0]\n",
    "med_preds = \"; \".join(sorted([term_names[pred] for pred in predictions[curr_pmid]]))\n",
    "med_sol = \"; \".join(sorted(list(dict.fromkeys([term_names[sol] for sol in solution[curr_pmid]]))))\n",
    "print(f\"F1 score for {curr_pmid}: {f1s[curr_pmid]}\")\n",
    "print(f\"Predicted terms ({len(predictions[curr_pmid])}) for PMID {curr_pmid}: \\n{med_preds}\")\n",
    "print(f\"\\nActual terms ({len(solution[curr_pmid])}) applied to PMID {curr_pmid}: \\n{med_sol}\")\n",
    "print(f\"\\nNumber of MeSH terms applied to all of {curr_pmid}'s references: {len(test_freqs[curr_pmid].keys())}\\n\")\n",
    "\n",
    "med_preds = \"; \".join(sorted([term_names[pred] for pred in predictions[med_pmids[1][0]]]))\n",
    "med_sol = \"; \".join(sorted([term_names[sol] for sol in solution[med_pmids[1][0]]]))\n",
    "print(f\"F1 score for {med_pmids[1][0]}: {f1s[med_pmids[1][0]]}\")\n",
    "print(f\"Predicted terms ({len(predictions[med_pmids[1][0]])}) for PMID {med_pmids[1][0]}: \\n{med_preds}\")\n",
    "print(f\"\\nActual terms ({len(solution[med_pmids[1][0]])}) applied to PMID {med_pmids[1][0]}: \\n{med_sol}\")\n",
    "print(f\"\\nNumber of MeSH terms applied to all of {med_pmids[1][0]}'s references: {len(test_freqs[med_pmids[1][0]].keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
