{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Default threshold function\n",
    "def get_f1(thresh_constant, term_freqs, solution):\n",
    "    # Predict\n",
    "    predictions = {}\n",
    "    for doc in term_freqs.keys():\n",
    "        mean_freq = sum(term_freqs[doc].values()) / len(term_freqs[doc])\n",
    "        predictions[doc] = [key for key, val in term_freqs[doc].items() if val > (mean_freq + thresh_constant)]\n",
    "        \n",
    "    # Get evaluation metrics\n",
    "    true_pos = 0\n",
    "    false_pos = 0\n",
    "    false_neg = 0\n",
    "    \n",
    "    for pmid in predictions:\n",
    "        true_pos += len([pred for pred in predictions[pmid] if pred in solution[pmid]])\n",
    "        false_pos += len([pred for pred in predictions[pmid] if pred not in solution[pmid]])\n",
    "        false_neg += len([sol for sol in solution[pmid] if sol not in predictions[pmid]])\n",
    "\n",
    "    if true_pos == 0:\n",
    "        precision = 0\n",
    "        recall = 0\n",
    "        f1 = 0\n",
    "    else:\n",
    "        precision = true_pos / (true_pos + false_pos)\n",
    "        recall = true_pos / (true_pos + false_neg)\n",
    "        f1 = (2 * precision * recall) / (precision + recall)\n",
    "    \n",
    "    return f1\n",
    "\n",
    "def train(term_freqs, solution):\n",
    "    curr_thresh_constant = 0.0\n",
    "    step_val = 0.001\n",
    "    f1s = []\n",
    "    \n",
    "    f1s.append(get_f1(curr_thresh_constant, term_freqs, solution))\n",
    "    f1s.append(get_f1(curr_thresh_constant + step_val, term_freqs, solution))\n",
    "    \n",
    "    curr_thresh_constant += step_val\n",
    "    next_thresh_f1 = get_f1(curr_thresh_constant + step_val, term_freqs, solution)\n",
    "    \n",
    "    while not (next_thresh_f1 < f1s[-1] and next_thresh_f1 < f1s[-2] and f1s[-1] < f1s[-2]):\n",
    "        curr_thresh_constant += step_val\n",
    "        f1s.append(get_f1(curr_thresh_constant, term_freqs, solution))\n",
    "        next_thresh_f1 = get_f1(curr_thresh_constant + step_val, term_freqs, solution)\n",
    "    \n",
    "    return curr_thresh_constant - step_val\n",
    "\n",
    "def predict(test_freqs, thresh_constant):\n",
    "    # Test it out\n",
    "    predictions = {}\n",
    "\n",
    "    # Predict\n",
    "    for doc in test_freqs.keys():\n",
    "        mean_freq = sum(test_freqs[doc].values()) / len(test_freqs[doc])\n",
    "        predictions[doc] = [key for key, val in test_freqs[doc].items() if val > (mean_freq + thresh_constant)]\n",
    "#        if mean_freq < thresh:\n",
    "#            predictions[doc] = [key for key, val in test_freqs[doc].items() if val > thresh]\n",
    "#        else:\n",
    "#            predictions[doc] = [key for key, val in test_freqs[doc].items() if val > mean_freq]\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in term frequencies and partition\n",
    "with open(\"./data/term_freqs_rev_3_all_terms.json\", \"r\") as handle:\n",
    "    temp = json.load(handle)\n",
    "\n",
    "docs_list = list(temp.keys())\n",
    "partition = int(len(docs_list) * .8)\n",
    "\n",
    "train_docs = docs_list[0:partition]\n",
    "test_docs = docs_list[partition:]\n",
    "\n",
    "# Load in solution values\n",
    "solution = {}\n",
    "docs_list = set(docs_list)\n",
    "with open(\"./data/pm_doc_term_counts.csv\", \"r\") as handle:\n",
    "    for line in handle:\n",
    "        line = line.strip(\"\\n\").split(\",\")\n",
    "        if line[0] in docs_list:\n",
    "            # Only use samples indexed with MeSH terms\n",
    "            terms = [term for term in line[1:] if term]\n",
    "            if terms:\n",
    "                solution[line[0]] = terms\n",
    "                \n",
    "# Build training/test data, ensure good solution data is available\n",
    "# Solution data is not always available because documents may not be\n",
    "# indexed - even though obviously some of their references have been indexed\n",
    "train_freqs = {}\n",
    "for doc in train_docs:\n",
    "    if doc in solution.keys():\n",
    "        train_freqs[doc] = temp[doc]\n",
    "\n",
    "test_freqs = {}\n",
    "for doc in test_docs:\n",
    "    if doc in solution.keys():\n",
    "        test_freqs[doc] = temp[doc]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in MeSH data\n",
    "term_names = {}\n",
    "mean_term_depths = {}\n",
    "with open(\"./data/mesh_data.tab\", \"r\") as handle:\n",
    "    for line in handle:\n",
    "        line = line.strip(\"\\n\").split(\"\\t\")\n",
    "        term_names[line[0]] = line[1]\n",
    "        mean_depth = 0\n",
    "        posits = [len(posit.split(\".\")) for posit in line[4].split(\",\")]\n",
    "        mean_term_depths[line[0]] = sum(posits) / len(posits)\n",
    "            \n",
    "uids = list(term_names.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned discrimination threshold constant: 0.009000000000000001\n",
      "\n",
      "Micro-averaged F1 from test set: 0.4798893772454778\n",
      "Micro-averaged precision from test set: 0.5024845355903074\n",
      "Micro-averaged recall from test set: 0.4592388424940755\n",
      "\n"
     ]
    }
   ],
   "source": [
    "thresh_constant = train(train_freqs, solution)\n",
    "print(f\"Learned discrimination threshold constant: {thresh_constant}\\n\")\n",
    "\n",
    "preds = predict(test_freqs, thresh_constant)\n",
    "\n",
    "true_pos = 0\n",
    "false_pos = 0\n",
    "false_neg = 0\n",
    "\n",
    "for pmid in preds:\n",
    "    true_pos += len([pred for pred in preds[pmid] if pred in solution[pmid]])\n",
    "    false_pos += len([pred for pred in preds[pmid] if pred not in solution[pmid]])\n",
    "    false_neg += len([sol for sol in solution[pmid] if sol not in preds[pmid]])\n",
    "\n",
    "if true_pos == 0:\n",
    "    mi_precision = 0\n",
    "    mi_recall = 0\n",
    "    mi_f1 = 0\n",
    "else:\n",
    "    mi_precision = true_pos / (true_pos + false_pos)\n",
    "    mi_recall = true_pos / (true_pos + false_neg)\n",
    "    mi_f1 = (2 * mi_precision * mi_recall) / (mi_precision + mi_recall)\n",
    "\n",
    "print(f\"Micro-averaged F1 from test set: {mi_f1}\")\n",
    "print(f\"Micro-averaged precision from test set: {mi_precision}\")\n",
    "print(f\"Micro-averaged recall from test set: {mi_recall}\\n\")\n",
    "\n",
    "ma_ps = []\n",
    "ma_rs = []\n",
    "ma_f1s = []\n",
    "\n",
    "for uid in uids:\n",
    "    true_pos = 0\n",
    "    false_pos = 0\n",
    "    false_neg = 0\n",
    "    \n",
    "    for pmid in preds:\n",
    "        if uid in preds[pmid] and uid in solution[pmid]:\n",
    "            true_pos += 1\n",
    "        if uid in preds[pmid] and uid not in solution[pmid]:\n",
    "            false_pos += 1\n",
    "        if uid in solution[pmid] and uid not in preds[pmid]:\n",
    "            false_neg += 1\n",
    "    \n",
    "    if true_pos == 0:\n",
    "        ma_precision = 0\n",
    "        ma_recall = 0\n",
    "        ma_f1 = 0\n",
    "    else:\n",
    "        ma_precision = true_pos / (true_pos + false_pos)\n",
    "        ma_recall = true_pos / (true_pos + false_neg)\n",
    "        ma_f1 = (2 * ma_precision * ma_recall) / (ma_precision + ma_recall)\n",
    "\n",
    "    if true_pos + false_pos + false_neg > 0:\n",
    "        ma_ps.append(ma_precision)\n",
    "        ma_rs.append(ma_recall)\n",
    "        ma_f1s.append(ma_f1)\n",
    "\n",
    "ma_f1 = sum(ma_f1s) / len(ma_f1s)\n",
    "ma_recall = sum(ma_rs) / len(ma_rs)\n",
    "ma_precision = sum(ma_ps) / len(ma_ps)\n",
    "\n",
    "print(f\"Macro-averaged F1 from test set: {ma_f1}\")\n",
    "print(f\"Macro-averaged precision from test set: {ma_precision}\")\n",
    "print(f\"Macro-averaged recall from test set: {ma_recall}\\n\")\n",
    "\n",
    "eb_ps = []\n",
    "eb_rs = []\n",
    "eb_f1s = []\n",
    "\n",
    "for pmid in preds:\n",
    "    true_pos = len([pred for pred in preds[pmid] if pred in solution[pmid]])\n",
    "    false_pos = len([pred for pred in preds[pmid] if pred not in solution[pmid]])\n",
    "    false_neg = len([sol for sol in solution[pmid] if sol not in preds[pmid]])\n",
    "\n",
    "    if true_pos == 0:\n",
    "        eb_precision = 0\n",
    "        eb_recall = 0\n",
    "        eb_f1 = 0\n",
    "    else:\n",
    "        eb_precision = true_pos / (true_pos + false_pos)\n",
    "        eb_recall = true_pos / (true_pos + false_neg)\n",
    "        eb_f1 = (2 * eb_precision * eb_recall) / (eb_precision + eb_recall)\n",
    "\n",
    "    eb_ps.append(eb_precision)\n",
    "    eb_rs.append(eb_recall)\n",
    "    eb_f1s.append(eb_f1)\n",
    "\n",
    "eb_f1 = sum(eb_f1s) / len(eb_f1s)\n",
    "eb_recall = sum(eb_rs) / len(eb_rs)\n",
    "eb_precision = sum(eb_ps) / len(eb_ps)\n",
    "\n",
    "print(f\"Example-based F1 from test set: {eb_f1}\")\n",
    "print(f\"Example-based precision from test set: {eb_precision}\")\n",
    "print(f\"Example-based recall from test set: {eb_recall}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_freqs, thresh_constant, solution):\n",
    "    predictions = {}\n",
    "    f1s = {}\n",
    "    f1s_all = {}\n",
    "    \n",
    "    # Predict\n",
    "    for doc in test_freqs.keys():\n",
    "        mean_freq = sum(test_freqs[doc].values()) / len(test_freqs[doc])\n",
    "        predictions[doc] = [key for key, val in test_freqs[doc].items() if val > (mean_freq + thresh_constant)]\n",
    "\n",
    "    for pmid in predictions:\n",
    "        true_pos = len([pred for pred in predictions[pmid] if pred in solution[pmid]])\n",
    "        false_pos = len([pred for pred in predictions[pmid] if pred not in solution[pmid]])\n",
    "        false_neg = len([sol for sol in solution[pmid] if sol not in predictions[pmid]])\n",
    "\n",
    "        if true_pos == 0:\n",
    "            precision = 0\n",
    "            recall = 0\n",
    "            f1 = 0\n",
    "        else:\n",
    "            precision = true_pos / (true_pos + false_pos)\n",
    "            recall = true_pos / (true_pos + false_neg)\n",
    "            f1 = (2 * precision * recall) / (precision + recall)\n",
    "        if len(predictions[pmid]) > 20:\n",
    "            f1s[pmid] = f1\n",
    "            \n",
    "        f1s_all[pmid] = f1\n",
    "        \n",
    "    return f1s, f1s_all, predictions\n",
    "        \n",
    "f1s, f1s_all, predictions = predict(test_freqs, 0.016, solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum F1: 0.9500000000000001\n",
      "Minimum F1: 0.07142857142857142\n"
     ]
    }
   ],
   "source": [
    "max_f1 = max(f1s.values())\n",
    "min_f1 = min(f1s.values())\n",
    "\n",
    "sorted_f1s = sorted([[key, val] for key, val in f1s.items()], key=lambda item: item[1], reverse=True)\n",
    "max_pmids = sorted_f1s[0:10]\n",
    "med_pmids = [samp for samp in sorted_f1s if samp[1] > 0.44 and samp[1] < 0.46][0:15]\n",
    "sorted_f1s_all = sorted([[key, val] for key, val in f1s_all.items()], key=lambda item: item[1], reverse=True)\n",
    "min_pmids = sorted_f1s_all[-10:]\n",
    "\n",
    "print(f\"Maximum F1: {max_f1}\")\n",
    "print(f\"Minimum F1: {min_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for 23314745: 0.9500000000000001\n",
      "Predicted terms (21) for PMID 23314745: \n",
      "Adolescent; Adult; Antiviral Agents; Child; Child, Preschool; Drug Therapy, Combination; Female; Genotype; Hepacivirus; Hepatitis C, Chronic; Humans; Interferon alpha-2; Interferon-alpha; Interleukins; Male; Polyethylene Glycols; Polymorphism, Single Nucleotide; Recombinant Proteins; Ribavirin; Treatment Outcome; Viral Load\n",
      "\n",
      "Actual terms (19) applied to PMID 23314745: \n",
      "Adolescent; Antiviral Agents; Child; Child, Preschool; Drug Therapy, Combination; Female; Genotype; Hepacivirus; Hepatitis C, Chronic; Humans; Interferon-alpha; Interleukins; Male; Polyethylene Glycols; Polymorphism, Single Nucleotide; Recombinant Proteins; Ribavirin; Treatment Outcome; Viral Load\n",
      "\n",
      "Number of MeSH terms applied to all of 23314745's references: 98\n",
      "\n",
      "F1 score for 28789709: 0.8571428571428571\n",
      "Predicted terms (21) for PMID 28789709: \n",
      "Adult; Aged; Aged, 80 and over; Antineoplastic Agents; Carcinoma, Renal Cell; Disease-Free Survival; Female; Humans; Indoles; Kidney Neoplasms; Male; Middle Aged; Niacinamide; Phenylurea Compounds; Prognosis; Protein Kinase Inhibitors; Pyrroles; Quality of Life; Sorafenib; Sunitinib; Treatment Outcome\n",
      "\n",
      "Actual terms (21) applied to PMID 28789709: \n",
      "Adult; Aged; Aged, 80 and over; Carcinoma, Renal Cell; China; Disease-Free Survival; Drug-Related Side Effects and Adverse Reactions; Female; Humans; Indoles; Male; Middle Aged; Neoplasm Metastasis; Niacinamide; Phenylurea Compounds; Protein Kinase Inhibitors; Pyrroles; Quality of Life; Sorafenib; Sunitinib; Treatment Outcome\n",
      "\n",
      "Number of MeSH terms applied to all of 28789709's references: 106\n"
     ]
    }
   ],
   "source": [
    "max_preds = \"; \".join(sorted([term_names[pred] for pred in predictions[max_pmids[0][0]]]))\n",
    "max_sol = \"; \".join(sorted(list(dict.fromkeys([term_names[sol] for sol in solution[max_pmids[0][0]]]))))\n",
    "print(f\"F1 score for {max_pmids[0][0]}: {f1s[max_pmids[0][0]]}\")\n",
    "print(f\"Predicted terms ({len(predictions[max_pmids[0][0]])}) for PMID {max_pmids[0][0]}: \\n{max_preds}\")\n",
    "print(f\"\\nActual terms ({len(solution[max_pmids[0][0]])}) applied to PMID {max_pmids[0][0]}: \\n{max_sol}\")\n",
    "print(f\"\\nNumber of MeSH terms applied to all of {max_pmids[0][0]}'s references: {len(test_freqs[max_pmids[0][0]].keys())}\\n\")\n",
    "\n",
    "max_preds = \"; \".join(sorted([term_names[pred] for pred in predictions[max_pmids[1][0]]]))\n",
    "max_sol = \"; \".join(sorted([term_names[sol] for sol in solution[max_pmids[1][0]]]))\n",
    "print(f\"F1 score for {max_pmids[1][0]}: {f1s[max_pmids[1][0]]}\")\n",
    "print(f\"Predicted terms ({len(predictions[max_pmids[1][0]])}) for PMID {max_pmids[1][0]}: \\n{max_preds}\")\n",
    "print(f\"\\nActual terms ({len(solution[max_pmids[1][0]])}) applied to PMID {max_pmids[1][0]}: \\n{max_sol}\")\n",
    "print(f\"\\nNumber of MeSH terms applied to all of {max_pmids[1][0]}'s references: {len(test_freqs[max_pmids[1][0]].keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for 25174707: 0\n",
      "Predicted terms (8) for PMID 25174707: \n",
      "DNA, Bacterial; Genes, Bacterial; Genetic Vectors; Humans; Mutation; Plasmids; Sequence Analysis, DNA; Staphylococcus aureus\n",
      "\n",
      "Actual terms (12) applied to PMID 25174707: \n",
      "Bacteriophages; Base Sequence; CRISPR-Associated Proteins; CRISPR-Cas Systems; Clustered Regularly Interspaced Short Palindromic Repeats; DNA, Viral; Immune Tolerance; Lysogeny; Molecular Sequence Data; Proviruses; Staphylococcus epidermidis; Transcription, Genetic\n",
      "\n",
      "Number of MeSH terms applied to all of 25174707's references: 72\n",
      "\n",
      "F1 score for 26679168: 0\n",
      "Predicted terms (17) for PMID 26679168: \n",
      "Animals; Cell Cycle; Cell Cycle Proteins; Cell Division; Computational Biology; DNA Damage; DNA Repair; HeLa Cells; Humans; Image Processing, Computer-Assisted; Microscopy, Confocal; Microscopy, Fluorescence; Phenotype; Protein Transport; RNA Interference; Reproducibility of Results; Signal Transduction\n",
      "\n",
      "Actual terms (4) applied to PMID 26679168: \n",
      "Datasets as Topic; Information Dissemination; Microscopy; Software\n",
      "\n",
      "Number of MeSH terms applied to all of 26679168's references: 71\n",
      "\n"
     ]
    }
   ],
   "source": [
    "examining = min_pmids[7][0]\n",
    "min_preds = \"; \".join(sorted([term_names[pred] for pred in predictions[examining]]))\n",
    "min_sol = \"; \".join(sorted(list(dict.fromkeys([term_names[sol] for sol in solution[examining]]))))\n",
    "print(f\"F1 score for {examining}: {f1s_all[examining]}\")\n",
    "print(f\"Predicted terms ({len(predictions[examining])}) for PMID {examining}: \\n{min_preds}\")\n",
    "print(f\"\\nActual terms ({len(solution[examining])}) applied to PMID {examining}: \\n{min_sol}\")\n",
    "print(f\"\\nNumber of MeSH terms applied to all of {examining}'s references: {len(test_freqs[examining].keys())}\\n\")\n",
    "\n",
    "min_preds = \"; \".join(sorted([term_names[pred] for pred in predictions[min_pmids[1][0]]]))\n",
    "min_sol = \"; \".join(sorted(list(dict.fromkeys([term_names[sol] for sol in solution[min_pmids[1][0]]]))))\n",
    "print(f\"F1 score for {min_pmids[1][0]}: {f1s_all[min_pmids[1][0]]}\")\n",
    "print(f\"Predicted terms ({len(predictions[min_pmids[1][0]])}) for PMID {min_pmids[1][0]}: \\n{min_preds}\")\n",
    "print(f\"\\nActual terms ({len(solution[min_pmids[1][0]])}) applied to PMID {min_pmids[1][0]}: \\n{min_sol}\")\n",
    "print(f\"\\nNumber of MeSH terms applied to all of {min_pmids[1][0]}'s references: {len(test_freqs[min_pmids[1][0]].keys())}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for 28794382: 0.4571428571428572\n",
      "Predicted terms (22) for PMID 28794382: \n",
      "Adult; Aged; Aged, 80 and over; Anticoagulants; Female; Fibrinolytic Agents; Hemorrhage; Humans; Male; Middle Aged; Nephrotic Syndrome; Renal Veins; Risk Assessment; Risk Factors; Thromboembolism; Thrombolytic Therapy; Time Factors; Treatment Outcome; Venous Thromboembolism; Venous Thrombosis; Warfarin; Young Adult\n",
      "\n",
      "Actual terms (13) applied to PMID 28794382: \n",
      "Adult; Factor Xa Inhibitors; Heparin; Humans; Male; Nephrotic Syndrome; Pulmonary Embolism; Pyridines; Renal Veins; Thiazoles; Treatment Outcome; Venous Thrombosis; Warfarin\n",
      "\n",
      "Number of MeSH terms applied to all of 28794382's references: 63\n",
      "\n",
      "F1 score for 28100192: 0.4571428571428572\n",
      "Predicted terms (22) for PMID 28100192: \n",
      "Adolescent; Adult; Blood Glucose; Congenital Abnormalities; Diabetes Mellitus, Type 1; Female; Gestational Age; Glycated Hemoglobin A; Humans; Hypoglycemia; Hypoglycemic Agents; Infant Mortality; Infant, Newborn; Insulin; Insulin Detemir; Insulin, Isophane; Insulin, Long-Acting; Pregnancy; Pregnancy Outcome; Pregnancy in Diabetics; Risk Factors; Stillbirth\n",
      "\n",
      "Actual terms (13) applied to PMID 28100192: \n",
      "Abnormalities, Drug-Induced; Adult; Diabetes Mellitus; Female; Humans; Hypoglycemic Agents; Infant, Newborn; Insulin Detemir; Perinatal Death; Pregnancy; Pregnancy in Diabetics; Prospective Studies; Research Design\n",
      "\n",
      "Number of MeSH terms applied to all of 28100192's references: 84\n"
     ]
    }
   ],
   "source": [
    "curr_pmid = med_pmids[4][0]\n",
    "med_preds = \"; \".join(sorted([term_names[pred] for pred in predictions[curr_pmid]]))\n",
    "med_sol = \"; \".join(sorted(list(dict.fromkeys([term_names[sol] for sol in solution[curr_pmid]]))))\n",
    "print(f\"F1 score for {curr_pmid}: {f1s[curr_pmid]}\")\n",
    "print(f\"Predicted terms ({len(predictions[curr_pmid])}) for PMID {curr_pmid}: \\n{med_preds}\")\n",
    "print(f\"\\nActual terms ({len(solution[curr_pmid])}) applied to PMID {curr_pmid}: \\n{med_sol}\")\n",
    "print(f\"\\nNumber of MeSH terms applied to all of {curr_pmid}'s references: {len(test_freqs[curr_pmid].keys())}\\n\")\n",
    "\n",
    "med_preds = \"; \".join(sorted([term_names[pred] for pred in predictions[med_pmids[1][0]]]))\n",
    "med_sol = \"; \".join(sorted([term_names[sol] for sol in solution[med_pmids[1][0]]]))\n",
    "print(f\"F1 score for {med_pmids[1][0]}: {f1s[med_pmids[1][0]]}\")\n",
    "print(f\"Predicted terms ({len(predictions[med_pmids[1][0]])}) for PMID {med_pmids[1][0]}: \\n{med_preds}\")\n",
    "print(f\"\\nActual terms ({len(solution[med_pmids[1][0]])}) applied to PMID {med_pmids[1][0]}: \\n{med_sol}\")\n",
    "print(f\"\\nNumber of MeSH terms applied to all of {med_pmids[1][0]}'s references: {len(test_freqs[med_pmids[1][0]].keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
